% -----------------------------------------------
% Template for ISMIR 2013
% (based on earlier ISMIR templates)
% -----------------------------------------------

\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage{ismir2013,amsmath,cite}
\usepackage{graphicx}

% Title.
% ------
\title{CSC 475 Final Project: Design Specification}

% Three addresses
% --------------
\threeauthors
{Lee Gauthier} {\tt lgauthie@uvic.ca}
{Robert Janzen} {\tt rjanzen@uvic.ca}
{Sondra Moyls} {\tt smoyls@uvic.ca}

\begin{document}
%
\maketitle
%

\section{Abstract}\label{sec:desoutline}
Our project aims to build an automatic chord recognition system using chroma vectors and supervised hidden markov 
models. We will then compare the accuracy of the system given four sets of input data: unaltered audio files, audio 
files with the background spectrum (transient elements) removed, audio files with removed harmonics (??? or is it 
polyphonic voice extraction???), and audio data with both the background spectrum and harmonics removed. We will 
also explore the success of using hidden markow models without chroma vectors, but by using voice extraction (???).

Hidden Markov Models (HMMs) are currently the most common method for predicting chord labels, and also 
produce high accuracy scores. Previous use of preprocessing of input data has also been explored and is
summarized in \cite{McVicar:00}.

\section{Tools}\label{sec:tools}

\subsection{Data Set}

For this project we will use the annotated Billboard 100 data set. This data set includes audio files for 
approximately 650 audio files from the Billboard top 100 chart between the years 1958 and 1991, as well as text
files containing the ground-truth for the chords on each beat interval\cite{Burgoyne:07}. The chords are labeled
as either maj, min, aug, dim, sus2, sus4, X, or N, where X and N imply no chord is present. For the scope of this
project we will classify inverted chords and 7th chords as one of the 8 previously stated classes.

\subsection{ACE Model}

For data preprocessing we will use ??????. 

Chroma vectors will be generated in accordance to the time intervals
given in the ground truth using the spectra2chroma and chromaFilter marsystems (we will investigate which approach
yields a better model).

<<Voice stuff?????>>

The output chroma vectors and the ground truth labels will be passed into an HMM function, available through
sci-kit, and will be used to build a transition matrix. The HMM will have 74 states, one for each chord of each
pitch class, plus the two non-chord states X and N. We will investigate further on the project how best
to parse out training and testing data for the model.

<<What does the output look like??? what do we get in the end???? What kinds of graphs??>


\section{Proposed Timeline}\label{sec:timeline}

March 10-16\newline
Rewrite design specification. Continue reading papers and solidify project goals. Test out using Python 
bindings with marsyas if haven't already.Start working on preprocessing and 
manipulating the ground truth data to output chroma vectors\newline
\newline

March 17-23\newline
Continue working on above.\newline
\newline

March 24-30\newline 
Continue working on above. Start working towards writing progress report.\newline
\newline

March 31-April 6\newline
Write progress report. Start working on getting the HMM classifier working.\newline
\newline

April 7 - April 13\newline
Put everything together. Start outputting results for final paper/slides\newline
\newline

April 14 - April 21\newline
Make presentation slides. un any final testing\newline
\newline

Tuesday April 22\newline
Report due and class presentation.\newline
\newline

\section{Roles of Each Member}

Robert -- Preprocessing of audio data by removing background spectrum \newline
Lee -- Voice extraction and modelling (?) \newline
Sondra -- Build chroma vector model, work on setting up HMM output\newline

\begin{thebibliography}{citations}

\bibitem {McVicar:00}
M. McVicar, et al.
"Automatic Chord Estimation for Audio: A Review of the State of the Art''
{\it IEEE/ACM Transactions on Audio, Speech, and Language Processing},
Vol.~22,No.~2, pp.~1-20, 2014.

\bibitem{Ueda:01}
Yushi Ueda, et al.
"HMM-Based Approach For Automatic Chord Detection Using Refined Acoustic Features''
{\it IEEE International Conference on Acoustics, Speech, and Signal Processing 2010},
pp.~5518--5521, 2010.

\bibitem{Varewyck:02}
Matthias Varewyck, et al.
"A Novel Chroma Representation of Polyphonic Music based on Multiple Pitch Tracking Techniques''
{\it 16th ACM International Conference on Multimedia},
2008.

\bibitem{Lee:03}
Kyogu Lee
"Automatic Chord Recognition from Audio Using Enhanced Pitch Class Profile''
{\it Center for Computer Research in Music and Acoustics, Stanford},
2006.

\bibitem{Papadopoulus:04}
Hélène Papadopoulos and George Tzanetakis
"Modeling Chord and Key Structure With Markov Logic''
{\it 13th International Society for Music Information Retrieval Conference},
pp.~127-132, 2012.

\bibitem{Richardson:05}
Matthew Richardson and Pedro Domingos
"Markov Logic Networks,''
{\it Department of Computer Science and Engineering, University of Washington, Seattle, WA},
pp.~1-43, 2006.

\bibitem{SciKit:06}
F. Pedregosa, et al.
"Scikit-learn: Machine Learning in Python"
{\it Journal of Machine Learning Research},
Vol.~12,pp.~2825-2830, 2011.

\bibitem{Burgoyne:07}
John Ashley Burgoyne, Jonathan Wild, and Ichiro Fujinaga
"An Expert Gound-Truth Set For Audio Chord Recognition and Music Analysis,"
{\it 12th International Society for Music Information Retrieval Conference},
pp.~633-638, 2011.

\bibitem{Burgoyne:08}
Nanzhu Jiang et al.
"Analyzing Chroma Feature Types for Automated Chord Recognition,"
{\it AES 42nd International Conference },
pp.~1-10, 2011.

\bibitem{Reed:09}
J.T. Reed, Yushi Ueda, S. Siniscalchi, Yuki Uchiyama, Shigeki Sagayama, C.-H. Lee
"Minimum Classification Error Training To Improve Isolated Chord Recognition"
{\it 10th International Society for Music Information Retrieval Conference (ISMIR 2009)},
pp.~609-614, 2009.

\bibitem{Mauch:10}
Matthias Mauch
"Automatic Chord Transcription from Audio Using Computation Models of Musical Context"
{\it School of Electronic Engineering and Computer Science, Queen Mary, University of London},
pp.~1-168, 2010.

\bibitem{FitzGerald:11}
Derry FitzGerald
"Harmonic/Percussive Separation Using Median Filtering"
{\it Proc\. of the 13th Int. Conference on Digital Audio Effects (DAFx-10), Graz, Austria, September 6-10, 2010},
pp.~1-4, 2010.

\bibitem{Blunsom:12}
Phil Blunsom
"Hidden Markov Models"
{\it Melbourne School of Engineering},
pp.~1-7, 2004.

\bibitem{Sumi:13}
Kouhei Sumi, KatsutoshiItoyama, Kazuyoshi Yoshii, Kazunori Komatani, Tetsuya Ogata, and Hiroshi G. Okuno
"Automatic Chord Recognition Based on Probabilistic Integration of Chord Transition and Bass Pitch Estimation"
{\it ISMIR 2008 - Session 1a - Harmony},
pp.~39-44, 2008.

\bibitem{Ryyananen:14}
Matti P. Ryyananen and Anssi P. Klapuri
"Automatic Transcription of Melody, Bass Line, and Chords in Polyphonic Music"
{\it Computer Music Journal, Volume 32, Number 3},
pp.~72-86, Fall 2008.

\bibitem{Lee:15}
Kyogu Lee and Malcolm Stanley
"Automatic Chord Recognition from Audio Using an HMM with Supervised Learning"
{\it AMCMM '06},
pp.~10-11, 2006.

\bibitem{Papadopoulus:16}
Hélène Papadopoulos and Geoffroy Peeters
"Large-Scale Study of Chord Estimation Algorithms Based on Chroma Representation and HMM"
{\it CBMI 2007},
pp.~53-60, 2007.

\end{thebibliography}

%\bibliography{ismir2013template}

\end{document}

